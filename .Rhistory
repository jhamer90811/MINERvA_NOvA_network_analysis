mean(scores.A + 2.63/36)
mean(scores.B + 2.63/36)
mean(scores + 1/12)
mean(scores + 1/18)
scores.A = c(31,25,29,26,22,22,29,30,29,19,24,32,16)/36
mean(scores.A)
sd(scores.A)
scores = c(scores.A,scores.B)
mean(scores)
sd(scores)
.110/.121
.110/ .158
t05 = 7
n = 8
t05n
t05*n
32/5 - 8 + 8/3
32*3
32*3 -8*15 + 40
A = matrix(c(2,1,3,1,2,3,3,3,6), 3, 3, byrow = TRUE)
A
det(A)
solve(A)
A = matrix(c(2,1,1,1,4,0,1,0,1), 3, 3, byrow = TRUE)
A
det(A)
solve(A)
eigen(A)
get.correlation = function(V){
n = nrow(V)
m = ncol(V)
C = matrix(NULL, n, m)
for (i in 1:n){
for(j in 1:m){
C[i,j] = V[i,j]/sqrt(V[i,i]*V[j,j])
}
}
return(C)
}
get.correlation = function(V){
n = nrow(V)
m = ncol(V)
C = matrix(c(1:n*m, NULL), n, m)
for (i in 1:n){
for(j in 1:m){
C[i,j] = V[i,j]/sqrt(V[i,i]*V[j,j])
}
}
return(C)
}
rho = get.correlation(A)
rho
4*30 + 3*40 + 3*50 + 4*60
4*30^2 + 3*40^2 + 3*50^2 + 4*60^2
30300*14-630^2
X = matrix(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,30,30,30,30,40,40,40,50,50,50,60,60,60,60),14,2)
X
y = c(55.8,59.1,54.8,54.6,43.1,42.2,45.2,31.6,30.9,30.8,17.5,20.5,17.2,16.9)
t(X)%*%y
solve(t(X)%*%X)%*%(t(X)%*%y)
library(boot)
boot(data,test.stat, R=999)
library(boot)
data = c(3,5,7,18,43,85,91,98,100,130,230,487)
test.stat = function(x){log(mean(x))}
boot.out = boot(data,test.stat,R=999)
boot.out
library(boot)
data = c(3,5,7,18,43,85,91,98,100,130,230,487)
test.stat = function(d,indices){log(mean(d[indices]))}
boot.out = boot(data,test.stat,R=999)
boot.out
library(boot)
data = c(3,5,7,18,43,85,91,98,100,130,230,487)
log.mean = function(d,indices){log(mean(d[indices]))}
boot.out = boot(data,log.mean,R=999)
boot.out
boot.out$t
boot.out$t0
boot.out$call
boot.out$statistic
boot.out[3]
boot.out
boot.out$strata
boot.out[4]
names(boot.out)
boot.out$t0
boot.out$bias
boot.out`Bootstrap Statistics`
log.mean.ci
log.mean.ci = boot.ci(boot.out)
log.mean.ci
log.mean.ci$percent
log.mean.ci$bca
ran.gen.exp = function(d,p){rexp(length(d), 1/p)}
boot.exp.out = boot(data, log.mean, R=999, sim = "parametric", ran.gen = ran.gen.exp, mle = mean(data))
boot.exp.out
boot.exp.ci = boot.ci(boot.exp.out)
boot.exp.ci
quantile(boot.exp.out,props = c(0.025,0.975))
quantile(boot.exp.out$t,props = c(0.025,0.975))
quantile(boot.exp.out$t,probs = c(0.025,0.975))
jeffrey = c(1,2,3)
jeffrey[-1]
jeffrey[-2]
log.mean(data)
n = length(data)
theta.hatn = log.mean(data)
theta.hat = rep(0,n)
for(i in 1:n){theta.hat[i] = log.mean(data[-i])}
theta.hat
n = length(data)
theta.hatn = log.mean(data)
theta.hat = rep(0,n)
for(i in 1:n){theta.hat[i] = log.mean(data[-i])}
theta.tilde = n*theta.hatn - (n-1)*theta.hat
theta.tilde
root.finder = function(g, a, b, tol, maxiters){
if(g(a)*g(b)>= 0){
print("Function has same sign at a and b.")
} else {
absdiff = b-a
iters = 0
while((iters < maxiters)&&(absdiff > tol)){
p = a + absdiff/2
if(g(p)*g(a)<0) {
b = p
} else {a = p}
maxdiff = b -a
iters = iters + 1
}
if(iters > maxiters){print("Maximum iterations reached.")
} else{return(list("root" = p, "function(root)" = g(p)))}
}
}
root.finder(function(x){x^2-1}, 0, 2, 0.00001, 100)
root.finder = function(g, a, b, tol, maxiters){
if(g(a)*g(b)>= 0){
print("Function has same sign at a and b.")
} else {
absdiff = b-a
iters = 0
while((iters < maxiters)&&(absdiff > tol)&&(g(p)!=0)){
p = a + absdiff/2
if(g(p)*g(a)<0) {
b = p
} else {a = p}
maxdiff = b -a
iters = iters + 1
}
if(iters > maxiters){print("Maximum iterations reached.")
} else{return(list("root" = p, "function(root)" = g(p)))}
}
}
root.finder(function(x){x^2-1}, 0, 2, 0.00001, 100)
root.finder = function(g, a, b, tol, maxiters){
if(g(a)*g(b)>= 0){
print("Function has same sign at a and b.")
} else {
absdiff = b-a
iters = 0
p = a + absdiff/2
while((iters < maxiters)&&(absdiff > tol)&&(g(p)!=0)){
p = a + absdiff/2
if(g(p)*g(a)<0) {
b = p
} else {a = p}
maxdiff = b -a
iters = iters + 1
}
if(iters > maxiters){print("Maximum iterations reached.")
} else{return(list("root" = p, "function(root)" = g(p)))}
}
}
root.finder(function(x){x^2-1}, 0, 2, 0.00001, 100)
4.682903-(-0.06785)
4.682903-(-0.03167626)
grades = c(80.23,81.61,89.56,83.13,29.52,94.6,54.84,81.7,63.17,82.32,13.07,95.43,94.63,79.65,96.91,90.12,76.79,82.78,78.88,83.68,96.3,35.1,62.72,94.62,80.91,93.48,98.27,88.88,63.46,44.83,18.61,86.85)
mean(grades)
stdev(grades)
sd(grades)
summary(grades)
grades[1]
len(grades[>=80])
len(grades[x>=80])
length(grades[x>=80])
grades[>80]
len(grades[90 <= grades ])
length(grades[90 <= grades ])
length(grades[80 <= grades < 90 ])
length(grades[80 <= grades && grades < 90 ])
length(grades[(80 <= grades) && (grades < 90) ])
length(grades[(80 <= grades) & (grades < 90) ])
length(grades[(70 <= grades) & (grades < 80) ])
length(grades[(60 <= grades) & (grades < 70) ])
length(grades[ (grades < 60) ])
length(grades[90 <= grades ])
A = length(grades[90 <= grades ])
B = length(grades[(80 <= grades) & (grades < 90) ])
C = length(grades[(70 <= grades) & (grades < 80) ])
D = length(grades[(60 <= grades) & (grades < 70) ])
F = length(grades[ (grades < 60) ])
dist = c(A = A, B = B, C = C, D = D, F = F)
dist
summary(grades)
2^10*factorial(10)
x = 0:10
sum(2^x*factorial(x))
2^9*factorial(9)
sum(3^x*factorial(x))
sum(4^x*factorial(x))
4*(90 - 24 - 0.15*(88) - 0.18*(88 + 91))
4*(80 - 24 - 0.15*(88) - 0.18*(88 + 91))
scores = matrix(c(5, 15, 28, 60, 23, 49, 0, 1, 12, 37, 16, 32, 16, 38, 52, 92, 32, 58, 49, 85, 43, 83, 21, 42, 17, 41, 46, 84, 15, 37, 48, 89, 16, 39, 48, 87, 34, 64, 45, 83, 48, 91, 43, 80, 24, 43, 18, 35, 48, 83, 31, 66, 21, 50),nrow = 27, ncol = 2, byrow = TRUE)
scores
rownames(scores) = c("common", "total")
colnames(scores) = c("common", "total")
scores
scores.data = data.frame(scores)
scores.data
scores.data$common = scores.data$common/57
scores.data
scores.data$common = scores.data$common*100
scores.data
corr(scores.data$common,scores.data$total)
cor(scores.data$common,scores.data$total)
mean(scores.data$common)
mean(scores.data$total)
sd(scores.data$total)
summary(scores.data$total)
data.frame(matrix(c(scores.data$common,0,0,0,0,scores.data$total,0,0,0,0),ncol = 2))
scores.data2 = data.frame(matrix(c(scores.data$common,0,0,0,0,scores.data$total,0,0,0,0),ncol = 2))
rownames(scores.data2)
colnames(scores.data2)
colnames(scores.data2) = c("common","total")
lm(total ~ common, data = scores.data2)
summary(lm(total ~ common, data = scores.data2))
final.scores = c(38.03,63.61,94.27,78.26,91.09,28.52,67.84,57.19,66.9,6.71,91.82,98.68,72.16,87.26, 65.86, 58.76, 86.82, 68.78, 76.78, 94.15, 19.57, 57.06, 94.82, 74.83, 90.78, 99.3, 60.86,56.19,32.79,4.17, 89.2)
summary(final.scores)
hist(final.scores)
quantile(final.scores, probs = c(0.03, 0.11, 0.51, 0.85))
plot(x = seq(from=1, to = length(final.scores)), y = sort(final.scores))
abline(h = 6.456)
abline(h = c(29.801, 69.794, 92.985))
sort(final.scores)
mean(scores.data2)
mean(scores.data2$common)
mean(scores.data2$total)
convert.R = function(x){return(x/0.135)}
convert.J = function(x){return(x/0.062)}
convert.H = function(x){return(x/0.046)}
results.RO = c(6,5.5, 5.5)
results.JO = c(4,4.5,4.5)
results.HO = c(4,3,3.5)
results.RH = c(7,6.5,7)
results.JH = c(5.5,6,5)
results.HH = c(5.5,4.5,4.5)
convert.R(results.RO)
mean(convert.R(results.RO))
convert.R(results.RH)
mean(convert.R(results.RH))
convert.J(results.JO)
mean(convert.J(results.JO))
convert.J(results.JH)
(convert.J(results.JH))
mean(convert.J(results.JH))
convert.H(results.HO)
mean(convert.H(results.HO))
convert.H(results.HH)
mean(convert.H(results.HH))
mean(c(5.7,5.5, 8.1,8.3))
mean(c(8,8,11.3,11.1))
mean(c(9.7,9.6,14.5,14.2))
mean(c(11,11,16.2,16.5))
mean(4,3.6,4.1,4.7)
mean(c(4,3.6,4.1,4.7))
mean(c(5.2,5.1,6.2,5.8))
mean(c(6.5,6.1,6.9,7.1))
mean(c(8,8,8.1,8))
print('Hey')
sum(9.85,9.2,6.95,5.8)/4
9.2+9.85
(9.2+9.85)/2
(6.95+5.8)/2
(6.95+9.85)/2
(9.2+5.8)/2
(7.5+8.4)/2
9.85 - 9.525 - 8.4 + 7.95
9.2 - 9.525 - 7.5 + 7.95
total.games = 368
bar.fee = 75
total.payout = 785
stats.df = data.frame(names = c("Max", "Matt", "Omar", "Delo", "Jesse", "Levi", "Nikki", "Calvin"),
row.names = "names")
stats.df$games.played = c(40,88,8,20,88,88,20,16)
stats.df$matches.played = stats.df$games.played/4
stats.df$proportion = round(stats.df$games.played/total.games,3)
stats.df$weekly.refund = 5*stats.df$matches.played
stats.df$bar.fee.refund = c(0,0,0,0,20,0,55,0)
stats.df$payout = round(stats.df$proportion*(total.payout-sum(stats.df$weekly.refund)-bar.fee)+
stats.df$weekly.refund + stats.df$bar.fee.refund, 2)
stats.df
sum(stats.df$payout)
grades = c(22,28,30,39,23,28,34,22,38,25,31,20,29,27,26,35,32,21,17,10,24,22,14,30,11,20,22,29,21,25,16,16,26,13,35,21)
grades[1:31]
grades = c(grades[1:31],grades[33:36])
percents = grades/40*100
grades.summary
summary(grades)
summary(percents)
sd(grades)
sd(percents)
hist(grades)
y = rnorm(1000, mean = 24.74, sd = 7.29)
hist(y)
hist(grades)
x = seq(min(grades),max(grades),length = 100)
hist(grades)
28+17
45/(44+28)
62.5*0.2+37.5*0.2+32.5*0.2
curve(dnorm(x,mean = 24.74, sd = 7.29))
hist(grades)
lines(x,dnorm(x,mean = 24.74,sd=7.29))
hist(grades,freq = TRUE)
hist(grades,freq = FALSE)
lines(x,dnorm(x,mean = 24.74,sd=7.29))
hist(grades,freq = FALSE, main = "Histogram of Exam 2 Grades")
lines(x,dnorm(x,mean = 24.74,sd=7.29))
quiz = mean(c(0,.5,0,1,5/7,0,0,0,1,1,1,1))*100
e1 = 70
e2 = 42.5
quiz*0.2 + e1*0.2 + e2*0.2
scores = c(60,84,56,59,33,52,83,88,54,36,76,93,50,68,39,69,79,73,73,56,74,70,40,76,67,88,59,47,73,70,86,73,33,61,53)
mean(scores)
32.86/.6
pnorm(1)
RCBD.mice.diet=function(){
# design variables:
treatment=as.factor(rep(c("Oats","Corn","Rice"),5))
cage=as.factor(rep(1:5,each=3))
# simulation values:
mu=-2
alpha1=-1
alpha2=1
alpha3=0
sigma_b2=1.44
sigma_2=0.64
# response vector:
body.fat.change = mu +
rep(c(alpha1,alpha2,alpha3),5) +
rep(rnorm(5,0,sqrt(sigma_b2)),each=3) +
rnorm(15,0,sqrt(sigma_2))
return(data.frame(obs=1:15,cage,treatment,body.fat.change))
}
test.df = RCBD.mice.diet()
test.df.summary()
summary(test.df)
test.df
test.lm = lm(body.fat.change ~ cage + treatment, data = test.df)
test.lm.summary()
summary(test.lm)
test.anova = anova(test.lm)
test.anova
test.anova$`Sum Sq`[3]
test.anova$`Sum Sq`[2]
test.df
test.anova$`Mean Sq`
MSE = NULL
MS_C = NULL
sigma_b2_hat = NULL
F_stat = NULL
p_val = NULL
for(i in 1:1000){
mice.df = RCBD.mice.diet()
mice.anova = anova(lm(body.fat.change ~ cage + treatment,data = mice.df))
MSE = c(MSE,mice.anova$`Mean Sq`[3])
MS_C = c(MS_C,mice.anova$`Mean Sq`[1])
sigma_b2_hat = c(sigma_b2_hat,(MS_C[length(MS_C)]-MSE[length(MSE)])/3)
F_stat = c(F_stat, MS_C[length(MS_C)]/MSE[length(MSE)])
p_val = c(p_val, pf(F_stat[length(F_stat)], 4, 10, lower.tail = FALSE))
}
hist(F_stat, prob=TRUE)
x = seq(min(F_stat),max(F_stat), length.out = 1000)
curve(df(x,4,10))
hist(F_stat, prob=TRUE)
lines(df(x,4,10))
mice.anova
sum(p_val<0.05)/1000
mice.anova
F_stat[1000]
x = seq(min(F_stat),max(F_stat),length.out = 1000)
hist(F_stat, prob = TRUE, main = "Histogram of F-Statistics")
lines(df(x,2,8, ncp = phi_hat), col = "red")
2+3+6+2+12+4+6+12+24
2+3+2+3+4+6+6+9+36
2340/80
253/80
397/60
pf(29.25,1,3,lower.tail = FALSE)
pf(3.16,3,3,lower.tail = FALSE)
pf(1.33,3,12,lower.tail = FALSE)
pf(1.33,2,12,lower.tail = FALSE)
pf(6.62,2,12,lower.tail = FALSE)
current.grade = 0.2*(90.8 + 92 + 92 + 95)
desired.grade = 90
(desired.grade - current.grade)*5
desired.grade = 80
(desired.grade - current.grade)*5
41**2
107*66
setwd("~/Documents/Fermilab/neutrino_topology_project/neutrino_topology_project")
setwd("~/Documents/Fermilab/neutrino_topology_project/neutrino_topology_project/MINERvA_NOvA_network_analysis")
minerva.data = read.csv('minerva-simple-00001-05000.csv')
nova.data = read.csv('nova-simple-00001-05000.csv')
names(minerva.data)
row.names(minerva.data)
minerva.data[1]
minerva.data[0]
minerva.data[1,:]
minerva.data[1;:]
minerva.data[1,1:]
minerva.data[1, 1:2]
minerva.data[1, 1:]
minerva.data[1, 1:ncol(minerva.data)]
minerva.data[1:1, 1:]
minerva.data[1,]
minerva.data = read.csv('minerva-simple-00001-05000.csv', row.names=1)
minerva.data[1,]
minerva.lm = lm(minerva.data$final_accuracy ~ ., data = minerva.data[3:90])
minerva.summary = summary(minerva.lm)
print(minerva.summary)
minerva.summary$cov.unscaled
plot(minerva.data)
minerva.summary
plot(final_accuracy ~ avg_ratio_features_to_depth, data = minerva.data)
plot(final_accuracy ~ avg_ratio_kerWidth_to_depth, data = minerva.data)
plot(final_accuracy ~ avg_ratio_features_to_kerWidth, data = minerva.data)
plot(minerva.lm)
plot(final_accuracy ~ net_depth_avg, data = minerva.data)
minerva.summary
hist(minerva.data$final_accuracy)
hist(minerva.data$initial_accuracy)
init_v_final.lm = lm(minerva.data$final_accuracy ~ minerva.data$initial_accuracy)
init_v_final.summary = summary(init_v_final.lm)
print(init_v_final.summary)
plot(minerva.data$final_accuracy~minerva.data$initial_accuracy)
minerva.data.prune = minerva.data
minerva.data['prop_1x1_conv']
features = c('final_accuracy', 'net_depth_avg', 'num_conv_layers', 'num_IP_layers','avg_IP_neurons','avg_IP_weights', 'avg_conv_ker_area', 'avg_num_conv_features','prop_conv_into_pool','prop_1x1_conv','prop_square_kernels','prop_horiz_kernels','prop_vert_kernels','avg_grid_reduction_area_consecutive','avg_grid_reduction_height_consecutive','avg_grid_reduction_width_consecutive','avg_grid_reduction_area_total','avg_grid_reduction_height_total','avg_grid_reduction_width_total','avg_stride_h','avg_stride_w','avg_ratio_features_to_depth','avg_ratio_features_to_kerArea','avg_ratio_features_to_kerWidth','avg_ratio_features_to_kerHeight','avg_ratio_kerArea_to_depth','avg_ratio_kerWidth_to_depth','avg_ratio_kerHeight_to_depth')
minerva.data.prune = minerva.data[features]
minerva.prune.lm = lm(final_accuracy ~ ., data = minerva.data.prune)
minerva.prune.summary = summary(minerva.prune.lm)
minerva.prune.summary
features[features=='avg_ratio_features_to_kerHeight']
to_remove = c('num_IP_layers','avg_num_conv_features', 'prop_square_kernels','prop_horiz_kernels', 'avg_grid_reduction_height_consecutive', 'avg_grid_reduction_area_total','avg_stride_h','avg_ratio_kerHeight_to_depth')
1 in c(1,2,3)
features[is.element(features, to_remove)]
features[!is.element(features, to_remove)]
minerva.data.prune = minerva.data.prune[features[!is.element(features,to_remove)]]
minerva.prune.lm = lm(minerva.data.prune)
minerva.prune.summary = summary(minerva.prune.lm)
minerva.prune.summ
minerva.prune.summary
minerva.prune[1,]
minerva.prune.data[1,]
minerva.data.prune[1,]
minerva.prune.lm = lm(final_accuracy ~ ., data = minerva.data.prune)
minerva.prune.summary = summary(minerva.prune.lm)
minerva.prune.summary
choose(28,2)
minerva.prune.qm = lm(final_accuracy ~ .^2, data=minerva.data.prune)
minerva.prune.qm.summary = summary(minerva.prune.qm)
minerva.prune.qm.summary
cor(minerva.data.prune)
cor(minerva.data.prune, use = 'complete.obs')
length(is.na(minerva.data.prune))
length(minerva.data.prune)
ncol(minerva.data.prune)
nrow(minerva.data.prune)
20*84177
length(minerva.data.prune[!is.numeric(minerva.data.prune)])
for(i in 1:10){}
for(i in 1:10){print(i)}
for(name in c('Jeff','Marie','Sue')){print(name)}
missing = is.na.data.frame(minerva.data)
View(missing)
sum(missing)
remove(missing)
sum(is.na.data.frame(minerva.data.prune))
missing = is.na.data.frame(minerva.data.prune)
minerva.data.prune[missing[1]]
minerva.data.prune[missing[2]]
minerva.data.prune[missing[1,1]]
missing[1,1]
minerva.data.prune[missing]
minerva.prune.complete = minerva.data.prune[complete.cases(minerva.data.prune),]
minerva.prune.lm = lm(final_accuracy~.,data = minerva.prune.complete)
minerva.prune.summary = summary(minerva.prune.lm)
minerva.prune.summary
minerva.prune.qm = lm(final_accuracy~.^2, data = minerva.prune.complete)
minerva.prune.qm.summary = summary(minerva.prune.qm)
plot(minerva.prune.qm)
minerva.prune.qm.summary
choose(19, 3)
minerva.prune.cm = lm(final_accuracy~.^3, data = minerva.prune.complete)
minerva.prune.cm.summary = summary(minerva.prune.cm)
minerva.prune.cm.summary
minerva.prune.logit = glm(final_accuracy~., family = binomial(link='logit'), data = minerva.prune.complete)
minerva.prune.logit.summary = summary(minerva.prune.logit)
minerva.prune.logit.summary
plot(minerva.prune.logit)
